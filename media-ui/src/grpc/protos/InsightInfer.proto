/*
 This proto file contains the SpeechInsightOrchestrator API. It takes
 a Voice stream as input and provides AI insights including Transcripts and
 Agent Assist. The insights are delivered through a separate Serving API
*/
syntax = "proto3";
option java_multiple_files = true;
package com.cisco.wccai.speech.aiinsight.v1;

import  "suggestions.proto";
import  "recognize.proto";
import  "messages.proto";
import  "tts.proto";
import  "utils.proto";
import  "virtualagent.proto";



/*
 Orchestrator service to be used by the clients while making speech insight requests
*/
service SpeechInsightOrchestrator {
    /*
     The Service that takes speech as input and produces multiple insights
    */
    rpc InferStreamingSpeechInsights( stream StreamingSpeechInferRequest)
        returns( stream StreamingSpeechInferResponse ) {}
    /*
     The Service that takes text as input and produces insights
    */
    rpc UnaryInferInsights(InferRequest)
        returns(InferResponse) {}

    /*
      The Service that takes config and org id and returns a list of bots for the specific provider
    */
    rpc ListVirtualAgents(ListVirtualAgentsRequest) returns(ListVirtualAgentsResponse) {}
}


/*
 Represents the streaming, long running message for the duration of the conversation
*/
message StreamingSpeechInferRequest {


    //Required - Multiple streaming messages needed
    oneof stream_speech_request {
        //The first message, once per streaming request
        StreamingRecognitionConfig streaming_config = 1;

        //The second message, once per streaming request
        InsightRequestConfig streaming_insight_config = 2;

        /*
        * Audio content, ideally in 100ms chunks, repeated
        * during the life of the message
        */
        bytes audio_content = 3;

        //The final message when the conversation is done.
        CloseStream close_stream = 4;

        //The text content
        string text = 6;

        //URL to stream the audio
        string url = 7 [deprecated=true];

    }

    //An optional message ID, if an identifier is needed. This is depricated use dialogId under InsightRequestConfig instead.
    string messageId = 5 [deprecated=true];

    // start timestamp for the url based transcripts, epoch time in millis
    int64 urlTimestamp = 12 [deprecated=true];

    com.cisco.wcc.ccai.v1.InputEvent inputEvent = 9; //Input event
    com.cisco.wcc.ccai.v1.DtmfEvents dtmfEvent = 10; //dtmf event
    com.cisco.wcc.ccai.v1.AudioConfig outputAudioConfig = 11; //output audio config
}

/*
 Represents the Infer request message
*/
message InferRequest {

    // insight request config
    InsightRequestConfig insight_config = 2;

    //The text content
    string text = 6;

    //message ID, an identifier
    string messageId = 5;
}

/*
 Represents the streaming recognition Config
*/

message StreamingRecognitionConfig {

    //Required. Provides information about audio
    RecognitionConfig config = 1;

    /* Optional. If false or omitted, the recognizer will perform
    continuous recognition (continuing to wait for and process audio
    even if the user pauses speaking) until the client closes the
    input stream (gRPC API) or until the maximum time limit has been
    reached. May return multiple StreamingRecognitionResults with
    the is_final flag set to true.
    */
    bool single_utterance = 2;

    /*
     Optional. Whether interim ASR results are needed.
     Such messages are returned with is_final=false
    */
    bool interim_results = 3;
}

/*
 Represents the configuration for the input Audio.
*/
message RecognitionConfig {

    /*
    Encoding for audio data sent in the request.
    Only MONO audio is supported
    */
    enum AudioEncoding {

        //Not specified. Unknown behavior
        ENCODING_UNSPECIFIED = 0;

        //Uncompressed 16-bit signed little-endian samples (Linear PCM).
        LINEAR16 = 1;

        //8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
        MULAW = 2;
    }

    AudioEncoding encoding = 3; //audio encoding

    //Sample rate in Hertz. Typically 8000 or 16000
    int32 sample_rate_hertz = 4;

    // BCP-47 code. Currently, only en-US is supported.
    string language_code = 5;

    /* Optional. Maximum number of recognition hypotheses to be returned.
    Specifically, the maximum number of `SpeechRecognitionAlternative` messages
    within each `SpeechRecognitionResult`.
    The server may return fewer than `max_alternatives`.
    Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
    one. If omitted, will return a maximum of one.
    */
    int32 max_alternatives = 6;

    /* Optional. If set to `true`, the server will attempt to filter out
    profanities, replacing all but the initial character in each filtered word
    with asterisks, e.g. "f***". If set to `false` or omitted, profanities
    won't be filtered out.
    Not yet supported.
    */
    bool profanity_filter = 7;

    /* Optional. array of [SpeechContext][google.cloud.speech.v1.SpeechContext].
    A means to provide context to assist the speech recognition. For more
    information, see [Phrase Hints](/speech-to-text/docs/basics#phrase-hints).
    */
    repeated SpeechContext speech_contexts = 8;

    /*
     Optional. If 'true', adds punctuation to recognition result hypotheses.
     Not yet supported.
    */
    bool enable_automatic_punctuation = 9;

    // Optional. Metadata regarding this request.
    RecognitionMetadata metadata = 10;

    //Channel number which has the caller stream in a multichannel file URL. Other streams will be considered as Agent Stream.
    //Default value will be based on RTMS usecase
    int32 caller_channel_number = 11 [deprecated=true];

    // Model definition to be used for recognition
    Model model = 12;

    //Configuration of barge-in behavior during the streaming of input audio.
    com.cisco.wcc.ccai.v1.InputBargeInConfig input_barge_in_config = 13;

}

message Model {
    // Name of the model to be used for recognition
    string model_name=1;
    // Variant of the model to be used for recognition
    string model_variant=2;
}

/*
 Represents the optional Recognition metadata
*/
message RecognitionMetadata {
    /*  The device used to make the recording.
    Examples 'Nexus 5X' or 'Poly com SoundStation IP 6000'
    or 'POTS' or 'VoIP' or 'Cardioid Microphone'.
    */
    string recording_device_name = 1;

    /* Mime type of the original audio file. For example audio/m4a,
    audio/x-alaw-basic, audio/mp3, audio/3gpp.
    A list of possible audio mime types is maintained at
    http://www.iana.org/assignments/media-types/media-types.xhtml#audio
    */
    string original_mime_type = 2;
}

/*
 Represents the speech context
*/
message SpeechContext {
    /* Optional. A list of strings containing words and phrases "hints" so that
    the speech recognition is more likely to recognize them. This can be used
    to improve the accuracy for specific words and phrases, for example, if
    specific commands are typically spoken by the user. This can also be used
    to add additional words to the vocabulary of the recognizer.
    */
    repeated string phrases = 1;
}

/*
The final message in the stream.
To be sent when the connection is terminated
*/
message CloseStream {
    //Currently, a free-form string. Will be logged for debugging.
    string reason = 1;
}

/*
    This message represents the configuration for the Insight Services
    that are requested by the gRPC call. Multiple messages can be
    requested for a given request. Appropriate entitlements/scopes are
    needed for each insight type
*/
message InsightRequestConfig{

    //Optional. A Unique identifier for the Client.Use for tracking purposes
    string clientId = 1;

    //Org Identifier (control hub) for which the insights need to be delivered
    string orgId = 2;

    //Identifier for the Conversation. Equivalent to Call ID, CallGUID, InteractionId etc
    string conversationId = 3;

    //Identifier for the party.
    enum Role {
        IVR=0; // Role - IVR
        CALLER=1; // Role - Caller
        AGENT=2; // Role - Agent
    }

    Role role = 4; //Role specifying IVR, Agent or caller

    /*
    Identifier for the individual leg, based on the party. GUID
    Used to track an individual leg within a conversation
    */
    string roleId = 5;

    //Identifier for tracking across all platforms. GUID for the request
    string trackingId = 6 [deprecated=true];

    /*
    Config, If available will default to Google Service Provider
    Else actual Service provider configuration will be used.
    */
    string ccaiConfigId = 7;

    enum RequestType {
        DEFAULT_UNSPECIFIED = 0; // Default Value
        VIRTUAL_AGENT = 1;      // Virtual Agent Request
        AGENT_ASSIST = 2;       // Agent Assist Request
    }

    // Type of the request indicating the call stage at which the API is called.
    RequestType requestType = 9;

    // Flag to restrict the inline responses
    bool restrictInlineResponse = 10;

    // Flag to enable partial response for VA
    bool enablePartialResponse = 11;

    //Any additional client information can be passed using this object
    com.cisco.wcc.ccai.v1.ConsumerInfo consumerInfo =12;

    //Optional field: populate if needed to call specific bot from the respective provider
    string virtualAgentId = 13;

     //Unique identifier for a dialog session within Conversation/Call/Interaction, Value will be unique per Conversation Id
     string legId = 14;

    //Auto increament for each dialog within call_leg, will be unique per legId
    int32 dialogId = 15;



}

/*
    This API is a Client side streaming API. Actual Insights are obtained
    through the Serving API. This response only provides a heartbeat
    Optional Message.
*/
message StreamingSpeechInferResponse {

    //Optional. Message ID in the request, will be returned as-is a acknowledgment
    string messageId = 1;

    //Optional. Request Status
    int32 status = 2;

    // Inline response returned to caller
    InferInsightResponse inferInsightResponse = 3;

}

/*
 Represents the Infer response message
*/
message InferResponse {

    //Optional. Message ID in the request, will be returned as-is a acknowledgment
    string messageId = 1;

    //Optional. Request Status
    int32 status = 2;

    // Inline response returned to caller
    InferInsightResponse inferInsightResponse = 3;

}

/*
 Represents the Infer insight response message
*/
message InferInsightResponse {

    com.cisco.wcc.ccai.v1.StreamingRecognitionResult  recognition_result      = 1; //Result of recognition

    com.cisco.wcc.ccai.v1.AgentAnswerResult agentAnswerResult = 5; //result of agent answer

    com.cisco.wcc.ccai.v1.VirtualAgentResult virtualAgentResult = 6; //result of virtual agent

    com.cisco.wcc.ccai.v1.Message message = 7; //message object
}

message ListVirtualAgentsRequest{
    string orgId    = 1;
    string configId = 2;
}


message ListVirtualAgentsResponse{
    //Indicates the list of bots for the selected provider
    repeated com.cisco.wcc.ccai.v1.VirtualAgent virtualAgents = 1;

}

