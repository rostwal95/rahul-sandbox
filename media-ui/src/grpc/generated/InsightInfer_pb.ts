//
//This proto file contains the SpeechInsightOrchestrator API. It takes
//a Voice stream as input and provides AI insights including Transcripts and
//Agent Assist. The insights are delivered through a separate Serving API

// @generated by protoc-gen-es v1.10.0 with parameter "target=ts"
// @generated from file InsightInfer.proto (package com.cisco.wccai.speech.aiinsight.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message, proto3, protoInt64 } from "@bufbuild/protobuf";
import { DtmfEvents, InputBargeInConfig, InputEvent, VirtualAgent, VirtualAgentResult } from "./virtualagent_pb.ts";
import { AudioConfig } from "./tts_pb.ts";
import { ConsumerInfo } from "./utils_pb.ts";
import { StreamingRecognitionResult } from "./recognize_pb.ts";
import { AgentAnswerResult } from "./suggestions_pb.ts";
import { Message as Message$1 } from "./messages_pb.ts";

/**
 *
 * Represents the streaming, long running message for the duration of the conversation
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.StreamingSpeechInferRequest
 */
export class StreamingSpeechInferRequest extends Message<StreamingSpeechInferRequest> {
  /**
   * Required - Multiple streaming messages needed
   *
   * @generated from oneof com.cisco.wccai.speech.aiinsight.v1.StreamingSpeechInferRequest.stream_speech_request
   */
  streamSpeechRequest: {
    /**
     * The first message, once per streaming request
     *
     * @generated from field: com.cisco.wccai.speech.aiinsight.v1.StreamingRecognitionConfig streaming_config = 1;
     */
    value: StreamingRecognitionConfig;
    case: "streamingConfig";
  } | {
    /**
     * The second message, once per streaming request
     *
     * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig streaming_insight_config = 2;
     */
    value: InsightRequestConfig;
    case: "streamingInsightConfig";
  } | {
    /**
     *
     * Audio content, ideally in 100ms chunks, repeated
     * during the life of the message
     *
     * @generated from field: bytes audio_content = 3;
     */
    value: Uint8Array;
    case: "audioContent";
  } | {
    /**
     * The final message when the conversation is done.
     *
     * @generated from field: com.cisco.wccai.speech.aiinsight.v1.CloseStream close_stream = 4;
     */
    value: CloseStream;
    case: "closeStream";
  } | {
    /**
     * The text content
     *
     * @generated from field: string text = 6;
     */
    value: string;
    case: "text";
  } | {
    /**
     * URL to stream the audio
     *
     * @generated from field: string url = 7 [deprecated = true];
     * @deprecated
     */
    value: string;
    case: "url";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * An optional message ID, if an identifier is needed. This is depricated use dialogId under InsightRequestConfig instead.
   *
   * @generated from field: string messageId = 5 [deprecated = true];
   * @deprecated
   */
  messageId = "";

  /**
   * start timestamp for the url based transcripts, epoch time in millis
   *
   * @generated from field: int64 urlTimestamp = 12 [deprecated = true];
   * @deprecated
   */
  urlTimestamp = protoInt64.zero;

  /**
   * Input event
   *
   * @generated from field: com.cisco.wcc.ccai.v1.InputEvent inputEvent = 9;
   */
  inputEvent?: InputEvent;

  /**
   * dtmf event
   *
   * @generated from field: com.cisco.wcc.ccai.v1.DtmfEvents dtmfEvent = 10;
   */
  dtmfEvent?: DtmfEvents;

  /**
   * output audio config
   *
   * @generated from field: com.cisco.wcc.ccai.v1.AudioConfig outputAudioConfig = 11;
   */
  outputAudioConfig?: AudioConfig;

  constructor(data?: PartialMessage<StreamingSpeechInferRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.StreamingSpeechInferRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "streaming_config", kind: "message", T: StreamingRecognitionConfig, oneof: "stream_speech_request" },
    { no: 2, name: "streaming_insight_config", kind: "message", T: InsightRequestConfig, oneof: "stream_speech_request" },
    { no: 3, name: "audio_content", kind: "scalar", T: 12 /* ScalarType.BYTES */, oneof: "stream_speech_request" },
    { no: 4, name: "close_stream", kind: "message", T: CloseStream, oneof: "stream_speech_request" },
    { no: 6, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "stream_speech_request" },
    { no: 7, name: "url", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "stream_speech_request" },
    { no: 5, name: "messageId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 12, name: "urlTimestamp", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 9, name: "inputEvent", kind: "message", T: InputEvent },
    { no: 10, name: "dtmfEvent", kind: "message", T: DtmfEvents },
    { no: 11, name: "outputAudioConfig", kind: "message", T: AudioConfig },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingSpeechInferRequest {
    return new StreamingSpeechInferRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingSpeechInferRequest {
    return new StreamingSpeechInferRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingSpeechInferRequest {
    return new StreamingSpeechInferRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingSpeechInferRequest | PlainMessage<StreamingSpeechInferRequest> | undefined, b: StreamingSpeechInferRequest | PlainMessage<StreamingSpeechInferRequest> | undefined): boolean {
    return proto3.util.equals(StreamingSpeechInferRequest, a, b);
  }
}

/**
 *
 * Represents the Infer request message
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.InferRequest
 */
export class InferRequest extends Message<InferRequest> {
  /**
   * insight request config
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig insight_config = 2;
   */
  insightConfig?: InsightRequestConfig;

  /**
   * The text content
   *
   * @generated from field: string text = 6;
   */
  text = "";

  /**
   * message ID, an identifier
   *
   * @generated from field: string messageId = 5;
   */
  messageId = "";

  constructor(data?: PartialMessage<InferRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.InferRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "insight_config", kind: "message", T: InsightRequestConfig },
    { no: 6, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "messageId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InferRequest {
    return new InferRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InferRequest {
    return new InferRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InferRequest {
    return new InferRequest().fromJsonString(jsonString, options);
  }

  static equals(a: InferRequest | PlainMessage<InferRequest> | undefined, b: InferRequest | PlainMessage<InferRequest> | undefined): boolean {
    return proto3.util.equals(InferRequest, a, b);
  }
}

/**
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.StreamingRecognitionConfig
 */
export class StreamingRecognitionConfig extends Message<StreamingRecognitionConfig> {
  /**
   * Required. Provides information about audio
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig config = 1;
   */
  config?: RecognitionConfig;

  /**
   * Optional. If false or omitted, the recognizer will perform
   * continuous recognition (continuing to wait for and process audio
   * even if the user pauses speaking) until the client closes the
   * input stream (gRPC API) or until the maximum time limit has been
   * reached. May return multiple StreamingRecognitionResults with
   * the is_final flag set to true.
   *
   * @generated from field: bool single_utterance = 2;
   */
  singleUtterance = false;

  /**
   *
   * Optional. Whether interim ASR results are needed.
   * Such messages are returned with is_final=false
   *
   * @generated from field: bool interim_results = 3;
   */
  interimResults = false;

  constructor(data?: PartialMessage<StreamingRecognitionConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.StreamingRecognitionConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "config", kind: "message", T: RecognitionConfig },
    { no: 2, name: "single_utterance", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "interim_results", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognitionConfig | PlainMessage<StreamingRecognitionConfig> | undefined, b: StreamingRecognitionConfig | PlainMessage<StreamingRecognitionConfig> | undefined): boolean {
    return proto3.util.equals(StreamingRecognitionConfig, a, b);
  }
}

/**
 *
 * Represents the configuration for the input Audio.
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig
 */
export class RecognitionConfig extends Message<RecognitionConfig> {
  /**
   * audio encoding
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig.AudioEncoding encoding = 3;
   */
  encoding = RecognitionConfig_AudioEncoding.ENCODING_UNSPECIFIED;

  /**
   * Sample rate in Hertz. Typically 8000 or 16000
   *
   * @generated from field: int32 sample_rate_hertz = 4;
   */
  sampleRateHertz = 0;

  /**
   * BCP-47 code. Currently, only en-US is supported.
   *
   * @generated from field: string language_code = 5;
   */
  languageCode = "";

  /**
   * Optional. Maximum number of recognition hypotheses to be returned.
   * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
   * within each `SpeechRecognitionResult`.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * one. If omitted, will return a maximum of one.
   *
   * @generated from field: int32 max_alternatives = 6;
   */
  maxAlternatives = 0;

  /**
   * Optional. If set to `true`, the server will attempt to filter out
   * profanities, replacing all but the initial character in each filtered word
   * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   * Not yet supported.
   *
   * @generated from field: bool profanity_filter = 7;
   */
  profanityFilter = false;

  /**
   * Optional. array of [SpeechContext][google.cloud.speech.v1.SpeechContext].
   * A means to provide context to assist the speech recognition. For more
   * information, see [Phrase Hints](/speech-to-text/docs/basics#phrase-hints).
   *
   * @generated from field: repeated com.cisco.wccai.speech.aiinsight.v1.SpeechContext speech_contexts = 8;
   */
  speechContexts: SpeechContext[] = [];

  /**
   *
   * Optional. If 'true', adds punctuation to recognition result hypotheses.
   * Not yet supported.
   *
   * @generated from field: bool enable_automatic_punctuation = 9;
   */
  enableAutomaticPunctuation = false;

  /**
   * Optional. Metadata regarding this request.
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.RecognitionMetadata metadata = 10;
   */
  metadata?: RecognitionMetadata;

  /**
   * Channel number which has the caller stream in a multichannel file URL. Other streams will be considered as Agent Stream.
   * Default value will be based on RTMS usecase
   *
   * @generated from field: int32 caller_channel_number = 11 [deprecated = true];
   * @deprecated
   */
  callerChannelNumber = 0;

  /**
   * Model definition to be used for recognition
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.Model model = 12;
   */
  model?: Model;

  /**
   * Configuration of barge-in behavior during the streaming of input audio.
   *
   * @generated from field: com.cisco.wcc.ccai.v1.InputBargeInConfig input_barge_in_config = 13;
   */
  inputBargeInConfig?: InputBargeInConfig;

  constructor(data?: PartialMessage<RecognitionConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 3, name: "encoding", kind: "enum", T: proto3.getEnumType(RecognitionConfig_AudioEncoding) },
    { no: 4, name: "sample_rate_hertz", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 5, name: "language_code", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "max_alternatives", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 7, name: "profanity_filter", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 8, name: "speech_contexts", kind: "message", T: SpeechContext, repeated: true },
    { no: 9, name: "enable_automatic_punctuation", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 10, name: "metadata", kind: "message", T: RecognitionMetadata },
    { no: 11, name: "caller_channel_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 12, name: "model", kind: "message", T: Model },
    { no: 13, name: "input_barge_in_config", kind: "message", T: InputBargeInConfig },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionConfig | PlainMessage<RecognitionConfig> | undefined, b: RecognitionConfig | PlainMessage<RecognitionConfig> | undefined): boolean {
    return proto3.util.equals(RecognitionConfig, a, b);
  }
}

/**
 *
 * Encoding for audio data sent in the request.
 * Only MONO audio is supported
 *
 * @generated from enum com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig.AudioEncoding
 */
export enum RecognitionConfig_AudioEncoding {
  /**
   * Not specified. Unknown behavior
   *
   * @generated from enum value: ENCODING_UNSPECIFIED = 0;
   */
  ENCODING_UNSPECIFIED = 0,

  /**
   * Uncompressed 16-bit signed little-endian samples (Linear PCM).
   *
   * @generated from enum value: LINEAR16 = 1;
   */
  LINEAR16 = 1,

  /**
   * 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
   *
   * @generated from enum value: MULAW = 2;
   */
  MULAW = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(RecognitionConfig_AudioEncoding)
proto3.util.setEnumType(RecognitionConfig_AudioEncoding, "com.cisco.wccai.speech.aiinsight.v1.RecognitionConfig.AudioEncoding", [
  { no: 0, name: "ENCODING_UNSPECIFIED" },
  { no: 1, name: "LINEAR16" },
  { no: 2, name: "MULAW" },
]);

/**
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.Model
 */
export class Model extends Message<Model> {
  /**
   * Name of the model to be used for recognition
   *
   * @generated from field: string model_name = 1;
   */
  modelName = "";

  /**
   * Variant of the model to be used for recognition
   *
   * @generated from field: string model_variant = 2;
   */
  modelVariant = "";

  constructor(data?: PartialMessage<Model>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.Model";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "model_variant", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Model {
    return new Model().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Model {
    return new Model().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Model {
    return new Model().fromJsonString(jsonString, options);
  }

  static equals(a: Model | PlainMessage<Model> | undefined, b: Model | PlainMessage<Model> | undefined): boolean {
    return proto3.util.equals(Model, a, b);
  }
}

/**
 *
 * Represents the optional Recognition metadata
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.RecognitionMetadata
 */
export class RecognitionMetadata extends Message<RecognitionMetadata> {
  /**
   *  The device used to make the recording.
   * Examples 'Nexus 5X' or 'Poly com SoundStation IP 6000'
   * or 'POTS' or 'VoIP' or 'Cardioid Microphone'.
   *
   * @generated from field: string recording_device_name = 1;
   */
  recordingDeviceName = "";

  /**
   * Mime type of the original audio file. For example audio/m4a,
   * audio/x-alaw-basic, audio/mp3, audio/3gpp.
   * A list of possible audio mime types is maintained at
   * http://www.iana.org/assignments/media-types/media-types.xhtml#audio
   *
   * @generated from field: string original_mime_type = 2;
   */
  originalMimeType = "";

  constructor(data?: PartialMessage<RecognitionMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.RecognitionMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recording_device_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "original_mime_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionMetadata {
    return new RecognitionMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionMetadata {
    return new RecognitionMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionMetadata {
    return new RecognitionMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionMetadata | PlainMessage<RecognitionMetadata> | undefined, b: RecognitionMetadata | PlainMessage<RecognitionMetadata> | undefined): boolean {
    return proto3.util.equals(RecognitionMetadata, a, b);
  }
}

/**
 *
 * Represents the speech context
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.SpeechContext
 */
export class SpeechContext extends Message<SpeechContext> {
  /**
   * Optional. A list of strings containing words and phrases "hints" so that
   * the speech recognition is more likely to recognize them. This can be used
   * to improve the accuracy for specific words and phrases, for example, if
   * specific commands are typically spoken by the user. This can also be used
   * to add additional words to the vocabulary of the recognizer.
   *
   * @generated from field: repeated string phrases = 1;
   */
  phrases: string[] = [];

  constructor(data?: PartialMessage<SpeechContext>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.SpeechContext";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrases", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeechContext {
    return new SpeechContext().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeechContext {
    return new SpeechContext().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeechContext {
    return new SpeechContext().fromJsonString(jsonString, options);
  }

  static equals(a: SpeechContext | PlainMessage<SpeechContext> | undefined, b: SpeechContext | PlainMessage<SpeechContext> | undefined): boolean {
    return proto3.util.equals(SpeechContext, a, b);
  }
}

/**
 *
 * The final message in the stream.
 * To be sent when the connection is terminated
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.CloseStream
 */
export class CloseStream extends Message<CloseStream> {
  /**
   * Currently, a free-form string. Will be logged for debugging.
   *
   * @generated from field: string reason = 1;
   */
  reason = "";

  constructor(data?: PartialMessage<CloseStream>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.CloseStream";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "reason", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CloseStream {
    return new CloseStream().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CloseStream {
    return new CloseStream().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CloseStream {
    return new CloseStream().fromJsonString(jsonString, options);
  }

  static equals(a: CloseStream | PlainMessage<CloseStream> | undefined, b: CloseStream | PlainMessage<CloseStream> | undefined): boolean {
    return proto3.util.equals(CloseStream, a, b);
  }
}

/**
 *
 * This message represents the configuration for the Insight Services
 * that are requested by the gRPC call. Multiple messages can be
 * requested for a given request. Appropriate entitlements/scopes are
 * needed for each insight type
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig
 */
export class InsightRequestConfig extends Message<InsightRequestConfig> {
  /**
   * Optional. A Unique identifier for the Client.Use for tracking purposes
   *
   * @generated from field: string clientId = 1;
   */
  clientId = "";

  /**
   * Org Identifier (control hub) for which the insights need to be delivered
   *
   * @generated from field: string orgId = 2;
   */
  orgId = "";

  /**
   * Identifier for the Conversation. Equivalent to Call ID, CallGUID, InteractionId etc
   *
   * @generated from field: string conversationId = 3;
   */
  conversationId = "";

  /**
   * Role specifying IVR, Agent or caller
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.Role role = 4;
   */
  role = InsightRequestConfig_Role.IVR;

  /**
   *
   * Identifier for the individual leg, based on the party. GUID
   * Used to track an individual leg within a conversation
   *
   * @generated from field: string roleId = 5;
   */
  roleId = "";

  /**
   * Identifier for tracking across all platforms. GUID for the request
   *
   * @generated from field: string trackingId = 6 [deprecated = true];
   * @deprecated
   */
  trackingId = "";

  /**
   *
   * Config, If available will default to Google Service Provider
   * Else actual Service provider configuration will be used.
   *
   * @generated from field: string ccaiConfigId = 7;
   */
  ccaiConfigId = "";

  /**
   * Type of the request indicating the call stage at which the API is called.
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.RequestType requestType = 9;
   */
  requestType = InsightRequestConfig_RequestType.DEFAULT_UNSPECIFIED;

  /**
   * Flag to restrict the inline responses
   *
   * @generated from field: bool restrictInlineResponse = 10;
   */
  restrictInlineResponse = false;

  /**
   * Flag to enable partial response for VA
   *
   * @generated from field: bool enablePartialResponse = 11;
   */
  enablePartialResponse = false;

  /**
   * Any additional client information can be passed using this object
   *
   * @generated from field: com.cisco.wcc.ccai.v1.ConsumerInfo consumerInfo = 12;
   */
  consumerInfo?: ConsumerInfo;

  /**
   * Optional field: populate if needed to call specific bot from the respective provider
   *
   * @generated from field: string virtualAgentId = 13;
   */
  virtualAgentId = "";

  /**
   * Unique identifier for a dialog session within Conversation/Call/Interaction, Value will be unique per Conversation Id
   *
   * @generated from field: string legId = 14;
   */
  legId = "";

  /**
   * Auto increament for each dialog within call_leg, will be unique per legId
   *
   * @generated from field: int32 dialogId = 15;
   */
  dialogId = 0;

  constructor(data?: PartialMessage<InsightRequestConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "clientId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "orgId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "conversationId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "role", kind: "enum", T: proto3.getEnumType(InsightRequestConfig_Role) },
    { no: 5, name: "roleId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "trackingId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "ccaiConfigId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 9, name: "requestType", kind: "enum", T: proto3.getEnumType(InsightRequestConfig_RequestType) },
    { no: 10, name: "restrictInlineResponse", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 11, name: "enablePartialResponse", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 12, name: "consumerInfo", kind: "message", T: ConsumerInfo },
    { no: 13, name: "virtualAgentId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 14, name: "legId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 15, name: "dialogId", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InsightRequestConfig {
    return new InsightRequestConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InsightRequestConfig {
    return new InsightRequestConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InsightRequestConfig {
    return new InsightRequestConfig().fromJsonString(jsonString, options);
  }

  static equals(a: InsightRequestConfig | PlainMessage<InsightRequestConfig> | undefined, b: InsightRequestConfig | PlainMessage<InsightRequestConfig> | undefined): boolean {
    return proto3.util.equals(InsightRequestConfig, a, b);
  }
}

/**
 * Identifier for the party.
 *
 * @generated from enum com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.Role
 */
export enum InsightRequestConfig_Role {
  /**
   * Role - IVR
   *
   * @generated from enum value: IVR = 0;
   */
  IVR = 0,

  /**
   * Role - Caller
   *
   * @generated from enum value: CALLER = 1;
   */
  CALLER = 1,

  /**
   * Role - Agent
   *
   * @generated from enum value: AGENT = 2;
   */
  AGENT = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(InsightRequestConfig_Role)
proto3.util.setEnumType(InsightRequestConfig_Role, "com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.Role", [
  { no: 0, name: "IVR" },
  { no: 1, name: "CALLER" },
  { no: 2, name: "AGENT" },
]);

/**
 * @generated from enum com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.RequestType
 */
export enum InsightRequestConfig_RequestType {
  /**
   * Default Value
   *
   * @generated from enum value: DEFAULT_UNSPECIFIED = 0;
   */
  DEFAULT_UNSPECIFIED = 0,

  /**
   * Virtual Agent Request
   *
   * @generated from enum value: VIRTUAL_AGENT = 1;
   */
  VIRTUAL_AGENT = 1,

  /**
   * Agent Assist Request
   *
   * @generated from enum value: AGENT_ASSIST = 2;
   */
  AGENT_ASSIST = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(InsightRequestConfig_RequestType)
proto3.util.setEnumType(InsightRequestConfig_RequestType, "com.cisco.wccai.speech.aiinsight.v1.InsightRequestConfig.RequestType", [
  { no: 0, name: "DEFAULT_UNSPECIFIED" },
  { no: 1, name: "VIRTUAL_AGENT" },
  { no: 2, name: "AGENT_ASSIST" },
]);

/**
 *
 * This API is a Client side streaming API. Actual Insights are obtained
 * through the Serving API. This response only provides a heartbeat
 * Optional Message.
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.StreamingSpeechInferResponse
 */
export class StreamingSpeechInferResponse extends Message<StreamingSpeechInferResponse> {
  /**
   * Optional. Message ID in the request, will be returned as-is a acknowledgment
   *
   * @generated from field: string messageId = 1;
   */
  messageId = "";

  /**
   * Optional. Request Status
   *
   * @generated from field: int32 status = 2;
   */
  status = 0;

  /**
   * Inline response returned to caller
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InferInsightResponse inferInsightResponse = 3;
   */
  inferInsightResponse?: InferInsightResponse;

  constructor(data?: PartialMessage<StreamingSpeechInferResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.StreamingSpeechInferResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "messageId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "status", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "inferInsightResponse", kind: "message", T: InferInsightResponse },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingSpeechInferResponse {
    return new StreamingSpeechInferResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingSpeechInferResponse {
    return new StreamingSpeechInferResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingSpeechInferResponse {
    return new StreamingSpeechInferResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingSpeechInferResponse | PlainMessage<StreamingSpeechInferResponse> | undefined, b: StreamingSpeechInferResponse | PlainMessage<StreamingSpeechInferResponse> | undefined): boolean {
    return proto3.util.equals(StreamingSpeechInferResponse, a, b);
  }
}

/**
 *
 * Represents the Infer response message
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.InferResponse
 */
export class InferResponse extends Message<InferResponse> {
  /**
   * Optional. Message ID in the request, will be returned as-is a acknowledgment
   *
   * @generated from field: string messageId = 1;
   */
  messageId = "";

  /**
   * Optional. Request Status
   *
   * @generated from field: int32 status = 2;
   */
  status = 0;

  /**
   * Inline response returned to caller
   *
   * @generated from field: com.cisco.wccai.speech.aiinsight.v1.InferInsightResponse inferInsightResponse = 3;
   */
  inferInsightResponse?: InferInsightResponse;

  constructor(data?: PartialMessage<InferResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.InferResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "messageId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "status", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "inferInsightResponse", kind: "message", T: InferInsightResponse },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InferResponse {
    return new InferResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InferResponse {
    return new InferResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InferResponse {
    return new InferResponse().fromJsonString(jsonString, options);
  }

  static equals(a: InferResponse | PlainMessage<InferResponse> | undefined, b: InferResponse | PlainMessage<InferResponse> | undefined): boolean {
    return proto3.util.equals(InferResponse, a, b);
  }
}

/**
 *
 * Represents the Infer insight response message
 *
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.InferInsightResponse
 */
export class InferInsightResponse extends Message<InferInsightResponse> {
  /**
   * Result of recognition
   *
   * @generated from field: com.cisco.wcc.ccai.v1.StreamingRecognitionResult recognition_result = 1;
   */
  recognitionResult?: StreamingRecognitionResult;

  /**
   * result of agent answer
   *
   * @generated from field: com.cisco.wcc.ccai.v1.AgentAnswerResult agentAnswerResult = 5;
   */
  agentAnswerResult?: AgentAnswerResult;

  /**
   * result of virtual agent
   *
   * @generated from field: com.cisco.wcc.ccai.v1.VirtualAgentResult virtualAgentResult = 6;
   */
  virtualAgentResult?: VirtualAgentResult;

  /**
   * message object
   *
   * @generated from field: com.cisco.wcc.ccai.v1.Message message = 7;
   */
  message?: Message$1;

  constructor(data?: PartialMessage<InferInsightResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.InferInsightResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recognition_result", kind: "message", T: StreamingRecognitionResult },
    { no: 5, name: "agentAnswerResult", kind: "message", T: AgentAnswerResult },
    { no: 6, name: "virtualAgentResult", kind: "message", T: VirtualAgentResult },
    { no: 7, name: "message", kind: "message", T: Message$1 },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InferInsightResponse {
    return new InferInsightResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InferInsightResponse {
    return new InferInsightResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InferInsightResponse {
    return new InferInsightResponse().fromJsonString(jsonString, options);
  }

  static equals(a: InferInsightResponse | PlainMessage<InferInsightResponse> | undefined, b: InferInsightResponse | PlainMessage<InferInsightResponse> | undefined): boolean {
    return proto3.util.equals(InferInsightResponse, a, b);
  }
}

/**
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.ListVirtualAgentsRequest
 */
export class ListVirtualAgentsRequest extends Message<ListVirtualAgentsRequest> {
  /**
   * @generated from field: string orgId = 1;
   */
  orgId = "";

  /**
   * @generated from field: string configId = 2;
   */
  configId = "";

  constructor(data?: PartialMessage<ListVirtualAgentsRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.ListVirtualAgentsRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "orgId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "configId", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListVirtualAgentsRequest {
    return new ListVirtualAgentsRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListVirtualAgentsRequest {
    return new ListVirtualAgentsRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListVirtualAgentsRequest {
    return new ListVirtualAgentsRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ListVirtualAgentsRequest | PlainMessage<ListVirtualAgentsRequest> | undefined, b: ListVirtualAgentsRequest | PlainMessage<ListVirtualAgentsRequest> | undefined): boolean {
    return proto3.util.equals(ListVirtualAgentsRequest, a, b);
  }
}

/**
 * @generated from message com.cisco.wccai.speech.aiinsight.v1.ListVirtualAgentsResponse
 */
export class ListVirtualAgentsResponse extends Message<ListVirtualAgentsResponse> {
  /**
   * Indicates the list of bots for the selected provider
   *
   * @generated from field: repeated com.cisco.wcc.ccai.v1.VirtualAgent virtualAgents = 1;
   */
  virtualAgents: VirtualAgent[] = [];

  constructor(data?: PartialMessage<ListVirtualAgentsResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "com.cisco.wccai.speech.aiinsight.v1.ListVirtualAgentsResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "virtualAgents", kind: "message", T: VirtualAgent, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListVirtualAgentsResponse {
    return new ListVirtualAgentsResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListVirtualAgentsResponse {
    return new ListVirtualAgentsResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListVirtualAgentsResponse {
    return new ListVirtualAgentsResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ListVirtualAgentsResponse | PlainMessage<ListVirtualAgentsResponse> | undefined, b: ListVirtualAgentsResponse | PlainMessage<ListVirtualAgentsResponse> | undefined): boolean {
    return proto3.util.equals(ListVirtualAgentsResponse, a, b);
  }
}

